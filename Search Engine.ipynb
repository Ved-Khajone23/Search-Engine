{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a3a102b-a4a3-49d2-aa88-ae9eb026a87c",
   "metadata": {},
   "source": [
    "# Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8327f-f116-4818-95b1-57732931acea",
   "metadata": {},
   "source": [
    "## Building a Complete AI Based Search Engine with Elasticsearch, Kubeflow and Katib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b3d4e5e-769f-4dac-9f45-2b1e2236f971",
   "metadata": {},
   "source": [
    "Building search systems is hard. Preparing them to work with machine learning is really hard. Developing a complete search engine framework integrated with AI is really really hard.\n",
    "So let’s make one. ✌️\n",
    "\n",
    "In this post, we’ll build a search engine from scratch and discuss on how to further optimize results by adding a machine learning layer using Kubeflow and Katib. This new layer will be capable of retrieving results considering the context of users and is the main focus of this article.\n",
    "\n",
    "As we’ll see, thanks to Kubeflow and Katib, final result is rather quite simple, efficient and easy to maintain."
   ]
  },
  {
   "attachments": {
    "9ae23604-67b4-4f50-a917-4cef44f7fea2.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "id": "79fce8c2-f649-4358-9a57-126a0a3d02c2",
   "metadata": {},
   "source": [
    "![Pipeline.jpg](attachment:9ae23604-67b4-4f50-a917-4cef44f7fea2.jpg)\n",
    "##### Complete pipeline executed by Kubeflow, responsible for orchestrating the whole system. Image by author."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cacad9-b109-49e5-b0d6-82ad1b0519dd",
   "metadata": {},
   "source": [
    "To understand the concepts in practice, we’ll implement the system with hands-on experience. As it’s been built on top of Kubernetes, you can use any infrastructure you like (given appropriate adaptations). We’ll be using Google Cloud Platform (GCP) in this post.\n",
    "\n",
    "We begin with a brief introduction to concepts and then move to the system implementation discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491dd786-7a34-461c-97e6-b6e0085d8bba",
   "metadata": {},
   "source": [
    "## 1.You Know, For Search\n",
    "\n",
    "If you receive the challenge of building a search system for your company or want to build one for your own, you’ll soon realize that the initial steps tend to be somewhat straightforward.\n",
    "\n",
    "First and foremost, the search engine must contain documents for retrieval. As we’ll be working with Elasticsearch, let’s use it as reference (for an introduction, please refer to their [Official Docs](https://www.elastic.co/guide/en/elasticsearch/guide/current/index.html)\n",
    "\n",
    "Documents should be uploaded to Elasticsearch following a JSON format. If, for instance, we are building a search engine for a fashion eCommerce store, here’s an example of a document:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b0184-7fae-4bcf-afdc-99f318882ebd",
   "metadata": {},
   "source": [
    "<img src=\"2.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99668f-2c18-4c23-85fc-d92d24b8b8ea",
   "metadata": {},
   "source": [
    "Then comes the retrieval step which in essencenvolves matching search queries with document fields:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63cff52-446e-404e-9623-4d115e768dc8",
   "metadata": {},
   "source": [
    "<img src=\"3next.jpg\" style=\"Width:400px;Height:400\" >\n",
    "<font size=\"1.9\">Example of document as uploaded to Elasticsearch. Image by author.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10cbba-4224-4376-b6cd-3d365de8e132",
   "metadata": {},
   "source": [
    "The ranking phase applies some mathematical rules such as [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) or [BM25F](https://en.wikipedia.org/wiki/Okapi_BM25) to figure out how to properly rank, sorting documents from best to worst match. It’d be something like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4887ce07-2d56-486d-9f49-906538b6d07f",
   "metadata": {},
   "source": [
    "<img src=\"4.jpg\" style=\"Width:400px;Height:400\" >\n",
    "<font size=\"1.9\">Example of properly ranked results as retrieved by Elasticsearch running BM25 scoring among the stored documents in the database. Image by author.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a21c0-2d92-459a-9120-cfd280fb4a61",
   "metadata": {},
   "source": [
    "Further optimization could leverage on specific fields of documents containing performance metrics. For instance, in the previous example, we have that the **Click Through Rate** (CTR, i.e., reason between clicks and total impressions) of the t-shirt is *CTR=0.36*. Another retrieval layer could be added using this information and favoring documents with better CTR to show at the top (also known as *“boosting”*):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca684a6-4b7c-4c9e-8dd7-d36f09a3d155",
   "metadata": {},
   "source": [
    "<img src=\"5.jpg\" style=\"Width:400px;Height:400\" >\n",
    "\n",
    "<font size=\"1.9\">Example adding performance metrics layer in retrieval rules. Previous second-best document raises to the top of the results. Image by author.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0987fc-f6ed-42aa-9376-fcae8909225c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "So far so good. But let’s see how to further optimize even more.\n",
    "\n",
    "Consider that each user has a specific context. Let’s take our fashion online store as an example again. Some of the traffic may come from southern regions where it may be warmer than regions from the north. They’d probably rather be exposed to lighter clothing than to winter specific products.\n",
    "\n",
    "More context can be added to the equation: we could distinguish customers based on their favorite brands, categories, colors, sizes, device used, average consuming ticket, profession, age and the list goes on and on…\n",
    "\n",
    "Doing so requires some extra tools as well. Let’s dive a bit deeper into that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210db871-db7b-4b9f-a8ed-1054335cf303",
   "metadata": {},
   "source": [
    "# 2. The Machine Learning Layer\r\n",
    "Learn-to-rank[ (LTR](https://en.wikipedia.org/wiki/Learning_to_rank)) is a field of machine learning that studies algorithms whose main goal is to properly rank a list of documents.\r\n",
    "\r\n",
    "It works essentially as any other learning algorithm: it requires a training dataset, suffers from problems such [as bias-varia](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)nce, each model has advantages over certain scenarios and so on.\r\n",
    "\r\n",
    "What basically changes is that the cost function for the training process is designed to let the algorithm learn about ranking and the output of the model is a value for how good of a match a given document is for a given query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092feafb-5e3e-4622-8f30-635a297b65fd",
   "metadata": {},
   "source": [
    "#### Mathematically, it’s simply given by:\n",
    "\n",
    "<img src=\"7.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed7b97-473f-4495-9292-0bb36549beed",
   "metadata": {},
   "source": [
    "'X' in our case comprehends all features we’d like to use to add context to the search. They can be values such as region of the user, their age, favorite brand, correlation between queries and documents fields and so on.\r\n",
    "\r\n",
    "f is the ranking model which is supposed to be trained and evaluated.\r\n",
    "\r\n",
    "Finally, J extends for Judgment and for us it’s an integer value that ranges from 0 (meaning the document is not a good match for a query given features) up to 4 (document is a very good match). We arrange documents from best to worst by using the judgments.\r\n",
    "\r\n",
    "Our main goal is to obtain f since it represents the ranking algorithm that adds the machine learning layer to the search results. And in order to obtain f, we need a dataset that already contains the values of the judgments otherwise we can’t train the models.\r\n",
    "\r\n",
    "As it turns out, finding those values can be quite challenging. While the details of how to do so won’t be covered here, this post has a thorough discussion on the subject; in a nutshell, we use clickstream data of users interactions with search engines (their clicks and purchases) to fit models whose variables yield a proxy for the judgment value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af723127-d7a2-4c1d-83e5-532e8fb7108f",
   "metadata": {},
   "source": [
    "<img src=\"8.jpg\" style=\"Width:400px;Height:400\" >\n",
    "\n",
    "Example of Graphical Model implemented on pyClickModels for finding relevance of documents associated to search engines results. Image by author."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bf14e-e13e-429e-8691-7aaf00076296",
   "metadata": {},
   "source": [
    "\n",
    "After computing the judgments, we are left with training the ranking models. Elasticsearch already offers a [learn-to-rank](https://github.com/o19s/elasticsearch-learning-to-rank) plugin which we’ll use in this implementation. The plugin offers various ranking algorithms ranging from decision trees to neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a624c01-f8cc-4cf8-b97c-fb95ecd5fecc",
   "metadata": {},
   "source": [
    "#### This is an example of the required training file:\n",
    "\n",
    "<img src=\"9.jpg\" style=\"Width:400px;Height:400\" >\n",
    "<font size=\"1.9\">Example of input file for the training step as required by Elasticsearch Learn2Rank plugin.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef9894-f7dd-44e0-986a-645d1c8db874",
   "metadata": {},
   "source": [
    "The idea is to register for each query (“women t-shirt”) all documents that were printed in the results page. For each, we compute their expected judgment and build the matrix of features 'X'.\n",
    "\n",
    "In practice, what will happen is that we’ll first prepare all this data and feed it to the Learn-To-Rank plugin of Elasticsearch which will result in a trained ranking model. It can then be used to add the personalization layer we are looking for.\n",
    "\n",
    "Further details on building X will be discussed soon.\r\n",
    "\r\n",
    "We are ready now to train the models. So far so good. But then, we still have a tricky problem: how to know if it’s working?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ab0ff-b1f1-4473-8a0e-9f22d579c44f",
   "metadata": {},
   "source": [
    "# 2.1 The Valuation Framework\n",
    "We could choose from several methods to check the performance of a ranking model. The one we’ll discuss here is the average rank metric based on what users either clicked or purchased (pySearchML focuses on purchase events only but clicks can be used interchangeably)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252ad0b-1a23-4670-9ad4-bd2bb6859c9f",
   "metadata": {},
   "source": [
    "#### Mathematically, it’s given by:\n",
    "\n",
    "<img src=\"11.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267cce6-7b5d-47c5-b569-172ad4ed5de2",
   "metadata": {},
   "source": [
    "The formula basically sums over each rank associated to each purchased (or clicked) item in reference to a complete list of documents. The denominator is simply the cardinality of how many items were summed over in the process (total items users either clicked or bought).\r\n",
    "\r\n",
    "In practice, what will happen is that, after training a ranking model, we’ll loop through the validation dataset (which contains what users searched and what they purchased) and use each search term to send a query to Elasticsearch. We then compare the results with what users bought to compute the appropriate average ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1a032-86dd-4ba3-8cc9-8ad9a103b309",
   "metadata": {},
   "source": [
    "<img src=\"12.jpg\" style=\"Width:400px;Height:400\" >\n",
    "<font size=\"1.9\">Example of the validation framework in practice. For each user in dataset, we use their search term to retrieve from ES results with the ranking model already implemented. We then take the average rank of the purchased items by users and their position in the ES result.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d14bae-1863-4eb5-96c3-51a62e30c556",
   "metadata": {},
   "source": [
    "The image above illustrates the concept. For each user, we send their search term to Elasticsearch which already contains the just recently trained model. We then compare the search results with what the user purchased and compute the rank. In the previous example, the red t-shirt appears at position 2 out of the 3 retrieved items. As it’s just one item that was purchased then rank=66%.\r\n",
    "\r\n",
    "We run the same computation to all users in the database and then average them all together for a final rank expression.\r\n",
    "\r\n",
    "Notice that the final rank metric must be lower than 50% otherwise the algorithm is just performing as a random selector of documents.\r\n",
    "\r\n",
    "This value is important as it’s used for selecting the best ranking model. That’s where we use Katib from Kubeflow.\r\n",
    "\r\n",
    "Let’s see now how to put all these concepts together and build the search engine:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeafe97-752d-4798-a087-4710addfa99c",
   "metadata": {},
   "source": [
    "# 3. Kubeflow Orchestration\n",
    "As discussed before, Kubeflow is the orchestrator for the pipeline processing. It has various responsibilities ranging from preparing data for Elasticsearch and for training to running the entire training process.\n",
    "\n",
    "It works by defining components and their respective tasks. For pySearchML, here’s the complete pipeline that was implemented:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21be4d-fcd4-4e8b-a8b2-3c474a6f4d36",
   "metadata": {},
   "source": [
    "The pipeline is defined by receiving various input parameters such as the bucket and model_name and we’ll be able to change those values at execution time (as we’ll see soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4543a8-cb69-41db-9c8c-88fab3c8fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline()\n",
    "def build_pipeline(\n",
    "    bucket='pysearchml',\n",
    "    es_host='elasticsearch.elastic-system.svc.cluster.local:9200',\n",
    "    force_restart=False,\n",
    "    train_init_date='20160801',\n",
    "    train_end_date='20160801',\n",
    "    validation_init_date='20160802',\n",
    "    validation_end_date='20160802',\n",
    "    test_init_date='20160803',\n",
    "    test_end_date='20160803',\n",
    "    model_name='lambdamart0',\n",
    "    ranker='lambdamart',\n",
    "    index='pysearchml'\n",
    "):\n",
    "    pvc = dsl.PipelineVolume(pvc='pysearchml-nfs')\n",
    "\n",
    "    prepare_op = dsl.ContainerOp(\n",
    "        name='prepare env',\n",
    "        image=f'gcr.io/{PROJECT_ID}/prepare_env',\n",
    "        arguments=[f'--force_restart={force_restart}', f'--es_host={es_host}', f'--bucket={bucket}', f'--model_name={model_name}'],\n",
    "        pvolumes={'/data': pvc}\n",
    "    )\n",
    "\n",
    "    val_reg_dataset_op = dsl.ContainerOp(\n",
    "        name='validation regular dataset',\n",
    "        image=f'gcr.io/{PROJECT_ID}/data_validation',\n",
    "        arguments=[f'--bucket={bucket}/validation/regular', f'--validation_init_date={validation_init_date}', f'--validation_end_date={validation_end_date}', f'--destination=/data/pysearchml/{model_name}/validation_regular'],\n",
    "        pvolumes={'/data': pvc}\n",
    "    ).set_display_name('Build Regular Validation Dataset').after(prepare_op)\n",
    "\n",
    "    val_train_dataset_op = dsl.ContainerOp(\n",
    "        name='validation train dataset',\n",
    "        image=f'gcr.io/{PROJECT_ID}/data_validation',\n",
    "        arguments=[f'--bucket={bucket}/validation/train', f'--validation_init_date={train_init_date}', f'--validation_end_date={train_end_date}', f'--destination=/data/pysearchml/{model_name}/validation_train'],\n",
    "        pvolumes={'/data': pvc}\n",
    "    ).set_display_name('Build Train Validation Dataset').after(prepare_op)\n",
    "\n",
    "    val_test_dataset_op = dsl.ContainerOp(\n",
    "        name='validation test dataset',\n",
    "        image=f'gcr.io/{PROJECT_ID}/data_validation',\n",
    "        arguments=[f'--bucket={bucket}/validation/test', f'--validation_init_date={test_init_date}', f'--validation_end_date={test_end_date}', f'--destination=/data/pysearchml/{model_name}/validation_test'],\n",
    "        pvolumes={'/data': pvc}\n",
    "    ).set_display_name('Build Test Validation Dataset').after(prepare_op)\n",
    "\n",
    "    train_dataset_op = dsl.ContainerOp(\n",
    "        name='train dataset',\n",
    "        image=f'gcr.io/{PROJECT_ID}/data_train',\n",
    "        command=['python', '/train/run.py'],\n",
    "        arguments=[f'--bucket={bucket}', f'--train_init_date={train_init_date}', f'--train_end_date={train_end_date}', f'--es_host={es_host}', f'--model_name={model_name}', f'--index={index}', f'--destination=/data/pysearchml/{model_name}/train'],\n",
    "        pvolumes={'/data': pvc}\n",
    "    ).set_display_name('Build Training Dataset').after(prepare_op)\n",
    "\n",
    "    katib_op = dsl.ContainerOp(\n",
    "        name='pySearchML Bayesian Optimization Model',\n",
    "        image=f'gcr.io/{PROJECT_ID}/model',\n",
    "        command=['python', '/model/launch_katib.py'],\n",
    "        arguments=[f'--es_host={es_host}', f'--model_name={model_name}', f'--ranker={ranker}', '--name=pysearchml', f'--train_file_path=/data/pysearchml/{model_name}/train/train_dataset.txt', f'--validation_files_path=/data/pysearchml/{model_name}/validation_regular', '--validation_train_files_path=/data/pysearchml/{model_name}/validation_train', f'--destination=/data/pysearchml/{model_name}/'],\n",
    "        pvolumes={'/data': pvc}\n",
    "    ).set_display_name('Katib Optimization Process').after(\n",
    "        val_reg_dataset_op, val_train_dataset_op, val_test_dataset_op, train_dataset_op\n",
    "    )\n",
    "\n",
    "    post_model_op = dsl.ContainerOp(\n",
    "        name='Post Best RankLib Model to ES',\n",
    "        image=f'gcr.io/{PROJECT_ID}/model',\n",
    "        command=['python', '/model/post_model.py'],\n",
    "        arguments=[f'--es_host={es_host}', f'--model_name={model_name}', f'--destination=/data/pysearchml/{model_name}/best_model.txt'],\n",
    "        pvolumes={'/data': pvc}\n",
    "    ).set_display_name('Post RankLib Model to ES').after(katib_op)\n",
    "\n",
    "    _ = dsl.ContainerOp(\n",
    "        name='Test Model',\n",
    "        image=f'gcr.io/{PROJECT_ID}/model',\n",
    "        command=['python', '/model/test.py'],\n",
    "        arguments=[f'--files_path=/data/pysearchml/{model_name}/validation_test', f'--index={index}', f'--es_host={es_host}', f'--model_name={model_name}'],\n",
    "        pvolumes={'/data': pvc}\n",
    "    ).set_display_name('Run Test Step').after(post_model_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb434d-99e3-49dc-b31f-db438313d604",
   "metadata": {},
   "source": [
    "#### Let’s see each component from the pipeline implementation and its purpose:\r",
    "<img src=\"13.jpg\" style=\"Width:400px;Height:400\" >\n",
    "<font size=\"1.9\">Step-by-step as implemented in pySearchML. Image by author.</font>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ba723e-fc25-46b3-ac45-82da888c940b",
   "metadata": {},
   "source": [
    "## 1. Prepare_Env\n",
    "Here’s how prepare_env component is defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd1854-67e2-4c29-9987-db0983afef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_op = dsl.ContainerOp(\n",
    "    name='prepare env',\n",
    "    image=f'gcr.io/{PROJECT_ID}/prepare_env',\n",
    "    arguments=[f'--force_restart={force_restart}', f'--es_host={es_host}', f'--bucket={bucket}', f'--model_name={model_name}'],\n",
    "    pvolumes={'/data': pvc}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c94c238-6b30-4d67-ae3c-c4e41de2be78",
   "metadata": {},
   "source": [
    "*Image* is a docker reference for the component to run in that step.\n",
    "*Arguments* are input parameters sent to the script executed in the Docker’s image ENTRYPOINT.\n",
    "*pvolumes* mounts the volume claim into \\data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12304de0-3c9d-4752-aef3-5338d42c03bb",
   "metadata": {},
   "source": [
    "## Here’s all files in prepare_env:\n",
    "<img src=\"14.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d427a-14c8-4f1a-a112-fcaa15b5635d",
   "metadata": {},
   "source": [
    "*run.py* is responsible for running queries against [BigQuery](https://cloud.google.com/bigquery) and preparing Elasticsearch. One of its input arguments is *model_name* which sets which folder to use as reference for processing data. *lambdamart0* is an algorithm that has already implemented to work with **Google Analytics(GA)** [Public sample](https://console.cloud.google.com/marketplace/product/obfuscated-ga360-data/obfuscated-ga360-data?filter=category%3Aanalytics&id=45f150ac-81d3-4796-9abf-d7a4f98eb4c6&project=pysearchml&folder=&organizationId=) dataset.\n",
    "*Dockerfile* bundles the whole code together and have as *ENTRYPOINT* the execution of the *run.py* script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dff098-49ae-49ef-8f5d-3ac2a45b5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM python:3.7.7-alpine3.12 as python\n",
    "\n",
    "COPY kubeflow/components/prepare_env /prepare_env\n",
    "WORKDIR /prepare_env\n",
    "COPY ./key.json .\n",
    "\n",
    "ENV GOOGLE_APPLICATION_CREDENTIALS=./key.json\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"python\", \"run.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57864caa-68a1-40b0-aa6f-ff496410c693",
   "metadata": {},
   "source": [
    "*lambdamart0* is a folder dedicated to an implementation of an algorithm with this respective name. It’s been built to process **GA public** data and works as an example of the system. Here’s the files it contains:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8a195-c2ab-45ed-bf5c-26083ec4e0d0",
   "metadata": {},
   "source": [
    "<img src=\"15.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff77dca-85d4-4847-bb1d-b01a110ea11d",
   "metadata": {},
   "source": [
    "*ga_data.sql* is a query responsible for retrieving documents from the **GA public** dataset and exporting it to Elasticsearch\n",
    "*es_mapping.json* is an index definition for each field of the documents\n",
    "features carries the value of X as discussed before. In *lambdamart0* example, it uses the **GA public** data as reference for building the features.\n",
    "Notice the feature called *name.json*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33572a82-95a1-48d1-a4e6-6d1508788e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "   \"query\": {\n",
    "       \"bool\": {\n",
    "           \"minimum_should_match\": 1,\n",
    "           \"should\": [\n",
    "               {\n",
    "                   \"match\": {\n",
    "                       \"name\": \"{{search_term}}\"\n",
    "                   }\n",
    "               }\n",
    "           ]\n",
    "       }\n",
    "    },\n",
    "    \"params\": [\"search_term\"],\n",
    "    \"name\": \"BM25 name\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0055d-6199-4f57-bd28-2b88d159fe33",
   "metadata": {},
   "source": [
    "It receives as input the parameter channel_group (channel that brought the user to our web store) and returns the CTR for that respective channel.\n",
    "\n",
    "This effectively prepares the model to distinguish from users their origin and how to rank each group. Specifically, users coming from paid sources might behave differently than those coming in through organic channels for instance. If the training is good enough, the ranking algorithm should be prepared to handle these situations.\n",
    "\n",
    "Still, this doesn’t tell much on how to personalize results by using intrinsic characteristics of each user. So, here’s one possibility for solving that. The feature *avg_customer_price.json* is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f53cb-187d-43b6-bbd5-56ae3c405310",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"query\": {\n",
    "        \"function_score\": {\n",
    "            \"query\": {\n",
    "                \"match_all\": {}\n",
    "            },\n",
    "            \"script_score\" : {\n",
    "                \"script\" : {\n",
    "                    \"params\": {\n",
    "                        \"customer_avg_ticket\": \"{{customer_avg_ticket}}\"\n",
    "                    },\n",
    "                    \"source\": \"return Math.log(1 + Math.abs(doc['price'].value - Float.parseFloat(params.customer_avg_ticket)))\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"params\": [\"customer_avg_ticket\"],\n",
    "    \"name\": \"customer_avg_ticket\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56563490-a1b8-457e-b382-3c475b147009",
   "metadata": {},
   "source": [
    "It receives as input the parameter *customer_avg_ticke* and returns for each document the log of the distance between the average user ticket and the price of the document.\n",
    "\n",
    "Now the ranking model can learn in the training phase how to manage the rank of each item based on how distant its price is to the average spending of the user on the website.\n",
    "\n",
    "With those three types of features we can add a complete personalization layer to a search system on top of Elasticsearch. Features can be anything as long as it can be abstracted into a valid search query and they must return some scoring metric eventually translated as our value **'X'**.\n",
    "\n",
    "For what follows in *prepare_env* component:\n",
    "\n",
    "Features are exported to Elasticsearch.\n",
    "An index is created on Elasticsearch that defines documents fields.\n",
    "Documents are queried from [BigQuery](https://cloud.google.com/bigquery) and uploaded into Elasticsearch.\n",
    "[RankLib requirements](https://github.com/WillianFuks/pySearchML/blob/master/kubeflow/components/prepare_env/run.py#L184:L185) are created (feature set store and so on).\n",
    "\n",
    "For implementing a new model with new data and features, just create another folder inside *prepare_env* (something like *modelname2*) and set how it will query data and upload them to Elasticsearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07dfe9c-6d7b-4cec-8286-e300a8546fdf",
   "metadata": {},
   "source": [
    "## 2. Validation Datasets\n",
    "This is a simple step. It consists of retrieving data from BigQuery containing what users searched, the context of the search and a list of products purchased.\n",
    "\n",
    "Here’s the BigQuery query used for retrieving the data. It basically selects all users, their searches and purchases and then combines with their context. An example of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c623ee-49ed-480d-8151-4a8c8c12cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"search_keys\": {\n",
    "    \"search_term\": \"office\",\n",
    "    \"channel_group\": \"direct\",\n",
    "    \"customer_avg_ticket\": \"13\"\n",
    "  },\n",
    "  \"docs\": [\n",
    "    {\"purchased\":[\"GGOEGOAQ012899\"]}\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed73e46-c207-4036-9925-6cd865b1b3af",
   "metadata": {},
   "source": [
    "*search_keys* can contain any available information that sets the context of customers. In the previous example, we’re using their channel group and average spending ticket on the website.\n",
    "\n",
    "This data is what we feed into the validation framework when computing the average rank as discussed before.\n",
    "\n",
    "Notice that the system builds three different validation datasets: one for the training period, another for the regular validation and finally the third is for the final testing step. The idea here is to analyze bias and variance for the trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4731c6-d059-4406-8142-9be1603e19a3",
   "metadata": {},
   "source": [
    "## 3. Training Dataset\n",
    "This is the component responsible for building the RankLib training file as discussed before. The complete [script](https://github.com/WillianFuks/pySearchML/blob/master/kubeflow/components/data/train/run.py) is actually quite simple. First, it downloads from BigQuery the input clickstream data which consists of users interactions on search pages. Here’s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbc3f4-5b99-4007-8cde-9ce83fe64282",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"search_keys\": {\n",
    "    \"search_term\": \"drinkware\",\n",
    "    \"channel_group\": \"direct\",\n",
    "    \"customer_avg_ticket\": \"20\"\n",
    "  },\n",
    "  \"judgment_keys\": [\n",
    "    {\n",
    "      \"session\": \n",
    "        [\n",
    "          {\"doc\":\"GGOEGDHC017999\",\"click\":\"0\",\"purchase\":\"0\"},\n",
    "          {\"doc\":\"GGOEADHB014799\",\"click\":\"0\",\"purchase\":\"0\"},\n",
    "          {\"doc\":\"GGOEGDHQ015399\",\"click\":\"1\",\"purchase\":\"0\"}\n",
    "        ]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ad06e-e0c8-4c82-8d0d-f866dd669b75",
   "metadata": {},
   "source": [
    "Notice that the keys associated to the search are aggregated together inside *search_keys*. Those values are the ones we send to Elasticsearch and replace appropriately each feature**X** as discussed in *prepare_env*. In the previous **JSON** example, we know that the user search context is:\n",
    "\n",
    "Searched for *drinkware*.\n",
    "Came to the store directly.\n",
    "Spent on average $20 on the website.\n",
    "\n",
    "*judgment_keys* combines users sessions composed of documents they saw on the search page and their interaction on a given document.\n",
    "\n",
    "This information is then sent to [pyClickModels](https://github.com/WillianFuks/pyClickModels) which then process the data and evaluates the judgment for each query-document pair. Result is a newline delimited JSON document as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b909ae-6a3a-4e38-bf13-1b05129cc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"search_term: bags|channel_group:organic_search|customer_avg_ticket:30\": {\n",
    "    \"GGOEGBRJ037299\": 0.3333377540111542,\n",
    "    \"GGOEGBRA037499\": 0.222222238779068,\n",
    "    \"GGOEGBRJ037399\": 0.222222238779068\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1675e-86f2-4f5c-854d-0fe10772a2d5",
   "metadata": {},
   "source": [
    "Notice that the value of the key is *search_term:bags|channel_group:organic|customer_avg_ticket:30.*\n",
    "\n",
    "As discussed before, we want our search engine to be aware of context and further optimize on top of that. As a consequence, judgments are extract based on the entire selected context, not just the search_term.\n",
    "\n",
    "By doing so, we can differentiate documents for each context and we’d have scenarios where a product receives judgment 4 for customers coming from northern regions and judgment 0 otherwise, as an example.\n",
    "\n",
    "Notice that the judgments values, as given by *pyClickModels*, ranges between 0 and 1. As the Learn-To-Rank Elasticsearch plugin is built on top of RankLib, this value is expected to range between integers 0 and 4, inclusive. What we do then is we transform the variables using their percentile as reference. Here’s the complete code for building the final judgment files:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2c9d3-c318-434d-85ed-ce2f3dcc2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_judgment_files(model_name: str) -> None:\n",
    "    model = DBN.DBNModel()\n",
    "    clickstream_files_path = f'/tmp/pysearchml/{model_name}/clickstream/'\n",
    "    model_path = f'/tmp/pysearchml/{model_name}/model/model.gz'\n",
    "    rmtree(os.path.dirname(model_path), ignore_errors=True)\n",
    "    os.makedirs(os.path.dirname(model_path))\n",
    "    judgment_files_path = f'/tmp/pysearchml/{model_name}/judgments/judgments.gz'\n",
    "    rmtree(os.path.dirname(judgment_files_path), ignore_errors=True)\n",
    "    os.makedirs(os.path.dirname(judgment_files_path))\n",
    "\n",
    "    model.fit(clickstream_files_path, iters=10)\n",
    "    model.export_judgments(model_path)\n",
    "\n",
    "    with gzip.GzipFile(judgment_files_path, 'wb') as f:\n",
    "        for row in gzip.GzipFile(model_path):\n",
    "            row = json.loads(row)\n",
    "            result = []\n",
    "            search_keys = list(row.keys())[0]\n",
    "            docs_judgments = row[search_keys]\n",
    "            search_keys = dict(e.split(':') for e in search_keys.split('|'))\n",
    "            judgments_list = [judge for doc, judge in docs_judgments.items()]\n",
    "\n",
    "            if all(x == judgments_list[0] for x in judgments_list):\n",
    "                continue\n",
    "\n",
    "            percentiles = np.percentile(judgments_list, [20, 40, 60, 80, 100])\n",
    "\n",
    "            judgment_keys = [{'doc': doc, 'judgment': process_judgment(percentiles, judgment)}\n",
    "                             for doc, judgment in docs_judgments.items()]\n",
    "            result = {'search_keys': search_keys, 'judgment_keys': judgment_keys}\n",
    "            f.write(json.dumps(result).encode() + '\\n'.encode())\n",
    "\n",
    "            \n",
    "def process_judgment(percentiles: list, judgment: float) -> int:\n",
    "    if judgment <= percentiles[0]:\n",
    "        return 0\n",
    "    if judgment <= percentiles[1]:\n",
    "        return 1\n",
    "    if judgment <= percentiles[2]:\n",
    "        return 2\n",
    "    if judgment <= percentiles[3]:\n",
    "        return 3\n",
    "    if judgment <= percentiles[4]:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0c660-3eb3-4737-8c82-6b95f5c0141b",
   "metadata": {},
   "source": [
    "### Here’s an example of the output of this step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90907bf9-edeb-4e91-9f84-7d35503ec5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"search_keys\": {\n",
    "    \"search_term\": \"office\",\n",
    "    \"channel_group\": \"organic_search\",\n",
    "    \"customer_avg_ticket\": \"24\"\n",
    "  },\n",
    "  \"judgment_keys\": [\n",
    "    {\"doc\": \"0\", \"judgment\": 0},\n",
    "    {\"doc\": \"GGOEGAAX0081\", \"judgment\": 4},\n",
    "    {\"doc\": \"GGOEGOAB016099\", \"judgment\": 0}\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976f392-0652-4f9f-bb97-0dd599979a8a",
   "metadata": {},
   "source": [
    "This data needs to be transformed into the required training file for RankLib. This is where we combine the information of judgments, documents, queries context with the features **X** (here’s the [code](https://github.com/WillianFuks/pySearchML/blob/master/kubeflow/components/data/train/run.py#L124) example for retrieving X from Elasticsearch).\n",
    "\n",
    "Each JSON row from previous step containing search context and judgment keys is looped over and sent as a query against Elasticsearch with the input parameters of the *search_keys*. The result will be each value of **X** as already defined from previous *prepare_env* step.\n",
    "\n",
    "End result is a training file that looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302638f-db5c-44d2-97d1-ad40e0943717",
   "metadata": {},
   "outputs": [],
   "source": [
    "0\tqid:0\t1:3.1791792\t2:0\t3:0.0\t4:2.3481672\n",
    "4\tqid:0\t1:3.0485907\t2:0\t3:0.0\t4:2.3481672\n",
    "0\tqid:0\t1:3.048304\t2:0\t3:0.0\t4:0\n",
    "0\tqid:0\t1:2.9526825\t2:0\t3:0.0\t4:0\n",
    "4\tqid:1\t1:2.7752903\t2:0\t3:0.0\t4:3.61228\n",
    "0\tqid:1\t1:2.8348017\t2:0\t3:0.0\t4:2.3481672"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d504993-aefe-4211-9cc5-b3c21d17d09b",
   "metadata": {},
   "source": [
    "For each query and for each document we have the estimated judgment as computed by *pyClickModels*, the id of the query and then a list of features X with their respective values.\n",
    "\n",
    "With this file, we can train now the ranking algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490a7356-e281-4e11-857e-a15a2e24df01",
   "metadata": {},
   "source": [
    "## 4. Katib Optimization\n",
    "[Katib](https://github.com/kubeflow/katib) is a tool from Kubeflow that offers an interface for automatic hyperparameter optimization. It has several available methods; Bayesian Optimization is the one selected in pySearchML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3155279b-3ce8-468e-af4b-f3b7348b1dc6",
   "metadata": {},
   "source": [
    "<img src=\"16.Gif\" style=\"Width:400px;Height:400\" >\n",
    "<font size=\"1\">Example of the algorithm Bayesian Optimization. As it samples more data points from the allowed domain, the closer it may get to the optimum value of a given function. In pySearchML, the domain is a set of variables that sets how a ranker should fit the data and the cost function it’s optimizing is the average rank. Image taken from Wikimedia Foundation.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53835215-3d39-40b9-8018-46154e0de2aa",
   "metadata": {},
   "source": [
    "What Katib does is it selects for each hyperparameter a new value based on a trade-off between [exploration-exploitation.](https://en.wikipedia.org/wiki/Bayesian_optimization) It then tests the new model and observe results which are used for future steps.\n",
    "\n",
    "For *pySearchML*, each parameter is an input of [RankLib](https://sourceforge.net/p/lemur/wiki/RankLib%20How%20to%20use/) which sets how the model will be fit (such as how many trees to use, total leaf nodes, how many neurons in a net and so on).\n",
    "\n",
    "Katib is defined through a [Custom Resource](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) of Kubernetes. We can run it by defining a YAML file and deploying it to the cluster, something like:\n",
    "\n",
    "***kubectl create -f katib_def.yaml***\n",
    "\n",
    "What Katib will do is read through the **YAML** file and start [trials](https://github.com/kubeflow/katib), each experimenting a specific value of hyperparameters. It can instantiate multiple pods running in parallel executing the code as specified in the experiment definition.\n",
    "\n",
    "Here are the files in this step:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c797771-575a-4ac0-bf31-a75bd2631bef",
   "metadata": {},
   "source": [
    "<img src=\"17.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c8bd8b-cc65-4082-9272-7797d8273f6c",
   "metadata": {},
   "source": [
    "*launch_katib.py* is responsible for launching Katib from a Python script. It receives input arguments, builds an YAML definition and use Kubernetes APIs to start Katib from the script itself.\n",
    "\n",
    "*experiment.json* works as a template for the definition of the experiment. Here’s its definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28876e03-0b55-4ff1-a100-bd73371bcaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"apiVersion\": \"kubeflow.org/v1alpha3\",\n",
    "  \"kind\": \"Experiment\",\n",
    "  \"metadata\": {\n",
    "    \"namespace\": \"kubeflow\",\n",
    "    \"name\": \"\",\n",
    "    \"labels\": {\n",
    "      \"controller-tools.k8s.io\": \"1.0\"\n",
    "    }\n",
    "  },\n",
    "  \"spec\": {\n",
    "    \"objective\": {\n",
    "      \"type\": \"minimize\",\n",
    "      \"objectiveMetricName\": \"Validation-rank\",\n",
    "      \"additionalMetricNames\": [\n",
    "        \"rank\"\n",
    "      ]\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "      \"algorithmName\": \"bayesianoptimization\"\n",
    "    },\n",
    "    \"parallelTrialCount\": 1,\n",
    "    \"maxTrialCount\": 2,\n",
    "    \"maxFailedTrialCount\": 1,\n",
    "    \"parameters\": [],\n",
    "    \"trialTemplate\": {\n",
    "      \"goTemplate\": {\n",
    "        \"rawTemplate\": {\n",
    "          \"apiVersion\": \"batch/v1\",\n",
    "          \"kind\": \"Job\",\n",
    "          \"metadata\":{\n",
    "            \"name\": \"{{.Trial}}\",\n",
    "            \"namespace\": \"{{.NameSpace}}\"\n",
    "          },\n",
    "          \"spec\": {\n",
    "            \"template\": {\n",
    "              \"spec\": {\n",
    "                \"restartPolicy\": \"Never\",\n",
    "                \"containers\": [\n",
    "                  {\n",
    "                    \"name\": \"{{.Trial}}\",\n",
    "                    \"image\": \"gcr.io/{PROJECT_ID}/model\",\n",
    "                    \"command\": [\n",
    "                      \"python /model/train.py --train_file_path={train_file_path} --validation_files_path={validation_files_path} --validation_train_files_path={validation_train_files_path} --es_host={es_host} --destination={destination} --model_name={model_name} --ranker={ranker} {{- with .HyperParameters}} {{- range .}} {{.Name}}={{.Value}} {{- end}} {{- end}}\"\n",
    "                    ],\n",
    "                    \"volumeMounts\": [\n",
    "                      {\n",
    "                        \"mountPath\": \"/data\",\n",
    "                        \"name\": \"pysearchmlpvc\",\n",
    "                        \"readOnly\": false\n",
    "                      }\n",
    "                    ]\n",
    "                  }\n",
    "                ],\n",
    "                \"volumes\": [\n",
    "                  {\n",
    "                    \"name\": \"pysearchmlpvc\",\n",
    "                    \"persistentVolumeClaim\": {\n",
    "                      \"claimName\": \"pysearchml-nfs\",\n",
    "                      \"readOnly\": false\n",
    "                    }\n",
    "                  }\n",
    "                ]\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff1569-a5a6-4895-8295-05ea315d6d11",
   "metadata": {},
   "source": [
    "It essentially defines how many pods to run in parallel and which Docker image to run for each trial along with its input command. Notice that the total pods running in parallel as well as maximum trials are hard-coded in *pySearchML*. Best approach would be to receive those parameters from the pipeline execution and replace them accordingly.\n",
    "\n",
    "*launch_katib.py* will read this template, build a final **YAML** definition and send it to Kubernetes which will start the Katib process.\n",
    "\n",
    "One of the input parameters is the *ranker* which is the ranking algorithm to select from RankLib (such as lambdaMart, listNet and so on). Each ranker has its own set of parameters, here’s the example for LambdaMart algorithm as implemented in **launch_katib.py:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f91599-23cd-400a-8ca0-5f87ac3debb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranker_parameters(ranker: str) -> List[Dict[str, Any]]:\n",
    "    return {\n",
    "        'lambdamart': [\n",
    "            {\"name\": \"--tree\", \"parameterType\": \"int\", \"feasibleSpace\": {\"min\": \"1\", \"max\": \"500\"}},\n",
    "            {\"name\": \"--leaf\", \"parameterType\": \"int\", \"feasibleSpace\": {\"min\": \"2\", \"max\": \"40\"}},\n",
    "            {\"name\": \"--shrinkage\", \"parameterType\": \"double\", \"feasibleSpace\": {\"min\": \"0.01\", \"max\": \"0.2\"}},\n",
    "            {\"name\": \"--tc\", \"parameterType\": \"int\", \"feasibleSpace\": {\"min\": \"-1\", \"max\": \"300\"}},\n",
    "            {\"name\": \"--mls\", \"parameterType\": \"int\", \"feasibleSpace\": {\"min\": \"1\", \"max\": \"10\"}}\n",
    "        ]\n",
    "    }.get(ranker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e5a52-0559-445f-8899-16e29b568ee6",
   "metadata": {},
   "source": [
    "Katib will select parameters from the domain defined above and run train.py where effectively RankLib is used to train the ranking models. An example of the command as implemented in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f507d-d45c-440c-ad14-62929a80e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = ('java -jar ranklib/RankLib-2.14.jar -ranker '\n",
    "       f'{ranker} -train {args.train_file_path} -norm sum -save '\n",
    "       f'{args.destination}/model.txt '\n",
    "       f'{(\" \".join(X)).replace(\"--\", \"-\").replace(\"=\", \" \")} -metric2t ERR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b324838-3369-497f-a905-6871c7c5c812",
   "metadata": {},
   "source": [
    "This string is sent to a *subprocess* call (notice it requires Java because of RankLib) which starts the training process. The result is a newly trained ranking model that can be exported to Elasticsearch.\n",
    "\n",
    "Just as the model is fit, [validate.py](https://github.com/WillianFuks/pySearchML/blob/master/kubeflow/components/model/validate.py) is invoked for computing the expected rank. The steps that take place are:\n",
    "\n",
    "The script loops through each JSON from the validation dataset.\n",
    "Each row contains the search context which is then used to build an Elasticsearch query. Here’s the query used by the model *lambdamart0* which we’ll use later on:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a5db6-8be3-464d-b69c-e40d59c7b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"query\": {\n",
    "        \"function_score\": {\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"bool\": {\n",
    "                            \"minimum_should_match\": 1,\n",
    "                            \"should\": [\n",
    "                                {\n",
    "                                    \"multi_match\": {\n",
    "                                        \"operator\": \"and\",\n",
    "                                        \"query\": \"{query}\",\n",
    "                                        \"type\": \"cross_fields\",\n",
    "                                        \"fields\": [\n",
    "                                            \"sku\",\n",
    "                                            \"name\",\n",
    "                                            \"category\"\n",
    "                                        ]\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"functions\": [\n",
    "                {\n",
    "                    \"field_value_factor\": {\n",
    "                        \"field\": \"performances.global.CTR\",\n",
    "                        \"factor\": 10,\n",
    "                        \"missing\": 0,\n",
    "                        \"modifier\": \"none\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"boost_mode\": \"sum\",\n",
    "            \"score_mode\": \"sum\"\n",
    "        }\n",
    "    },\n",
    "    \"rescore\": {\n",
    "        \"window_size\": \"{window_size}\",\n",
    "        \"query\": {\n",
    "            \"rescore_query\": {\n",
    "                \"sltr\": {\n",
    "                    \"params\": \"{search_keys}\",\n",
    "                    \"model\": \"{model_name}\"\n",
    "                }\n",
    "            },\n",
    "            \"rescore_query_weight\": 20,\n",
    "            \"query_weight\": 0.1,\n",
    "            \"score_mode\": \"total\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f29fd-09c0-4117-9b9e-f58b8ab3120c",
   "metadata": {},
   "source": [
    "Given the recently built query, a request is sent to Elasticsearch.\n",
    "A comparison happens between the search results and purchased documents.\n",
    "Here’s the code responsible for building the Elasticsearch query:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ac49c-fb74-4d87-beae-9af82271e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_es_query(\n",
    "    search_keys: Dict[str, Any],\n",
    "    model_name: str,\n",
    "    es_batch: int = 1000\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Builds the Elasticsearch query to be used when retrieving data.\n",
    "    Args\n",
    "    ----\n",
    "      args: NamedTuple\n",
    "        args.search_keys: Dict[str, Any]\n",
    "            Search query sent by the customer as well as other variables that sets its\n",
    "            context, such as region, favorite brand and so on.\n",
    "        args.model_name: str\n",
    "            Name of RankLib model saved on Elasticsearch\n",
    "        args.index: str\n",
    "            Index on Elasticsearch where to retrieve documents\n",
    "        args.es_batch: int\n",
    "            How many documents to retrieve\n",
    "    Returns\n",
    "    -------\n",
    "      query: str\n",
    "          String representation of final query\n",
    "    \"\"\"\n",
    "    # it's expected that a ES query will be available at:\n",
    "    # ./queries/{model_name}/es_query.json\n",
    "    query = open(f'queries/{model_name}/es_query.json').read()\n",
    "    query = json.loads(query.replace('{query}', search_keys['search_term']))\n",
    "    # We just want to retrieve the id of the document to evaluate the ranks between\n",
    "    # customers purchases and the retrieve list result\n",
    "    query['_source'] = '_id'\n",
    "    query['size'] = es_batch\n",
    "    query['rescore']['window_size'] = 50  # Hardcoded to optimize first 50 skus\n",
    "    query['rescore']['query']['rescore_query']['sltr']['params'] = search_keys\n",
    "    query['rescore']['query']['rescore_query']['sltr']['model'] = model_name\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0609b26-506d-453a-b0a3-3605e7b30a65",
   "metadata": {},
   "source": [
    "Notice that the parameter *rescore_query* triggers the machine learning layer on Elasticsearch learn-to-rank plugin.\n",
    "\n",
    "Finally, the function *compute_rank* puts it all together as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b1e8a-7fe7-4d8a-b394-e622147ffe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rank(\n",
    "    search_arr: List[str],\n",
    "    purchase_arr: List[List[Dict[str, List[str]]]],\n",
    "    rank_num: List[float],\n",
    "    rank_den: List[float],\n",
    "    es_client: Elasticsearch\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Sends queries against Elasticsearch and compares results with what customers\n",
    "    purchased. Computes the average rank position of where the purchased document falls\n",
    "    within the retrieved items.\n",
    "    Args\n",
    "    ----\n",
    "      search_arr: List[str]\n",
    "          Searches made by customers as observed in validation data. We send those\n",
    "          against Elasticsearch and compare results with purchased data\n",
    "      purchase_arr: List[List[Dict[str, List[str]]]]\n",
    "          List of documents that were purchased by customers\n",
    "      rank_num: List[float]\n",
    "          Numerator value of the rank equation. Defined as list to emulate a pointer\n",
    "      rank_den: List[float]\n",
    "      es_client: Elasticsearch\n",
    "          Python Elasticsearch client\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    if not search_arr:\n",
    "        return\n",
    "\n",
    "    request = os.linesep.join(search_arr)\n",
    "    response = es_client.msearch(body=request, request_timeout=60)\n",
    "\n",
    "    for hit in response['responses']:\n",
    "        docs = [doc['_id'] for doc in hit['hits'].get('hits', [])]\n",
    "\n",
    "        if not docs or len(docs) < 2:\n",
    "            continue\n",
    "\n",
    "        purchased_docs = [\n",
    "            docs for purch in purchase_arr[idx] for docs in purch['purchased']\n",
    "        ]\n",
    "        ranks = np.where(np.in1d(docs, purchased_docs))[0]\n",
    "        idx += 1\n",
    "\n",
    "        if ranks.size == 0:\n",
    "            continue\n",
    "\n",
    "        rank_num[0] += ranks.sum() / (len(docs) - 1)\n",
    "        rank_den[0] += ranks.size\n",
    "\n",
    "    print('rank num: ', rank_num[0])\n",
    "    print('rank den: ', rank_den[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b419079-2564-4de8-a5e2-bffe74f03e79",
   "metadata": {},
   "source": [
    "Katib instantiate [sidecars pods](https://www.magalix.com/blog/the-sidecar-pattern) which keeps reading through the stdout of the training pod. When it identifies the string ***Validation-rank=(...)***, it uses the value as the result for the optimization process.\n",
    "\n",
    "A persistent volume is used in the process to save the definition of the best model trained by Katib which is used by our next component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f2595-c909-427f-9930-77b0b5b9646d",
   "metadata": {},
   "source": [
    "## 5. Post RankLib Model\n",
    "The most difficult parts are done already. Now what happens is the script simply goes after the definition of the best model as saved in a text file and uploads it to Elasticsearch.\n",
    "\n",
    "Notice that one of the main advantages with this design is that this component could export the model to a production Elasticsearch while the whole optimization could happen on a staging replica engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e3e3cc-1e59-4099-9fee-8d8a1b3d823a",
   "metadata": {},
   "source": [
    "## 6. Final Testing\n",
    "Finally, as the best model is exported to Elasticsearch, the system has at its disposal the best optimized ranking model. In this step, a final validation is executed in order to verify not only that everything worked fine as well as for providing further information on whether the system is suffering from bias-variance.\n",
    "\n",
    "That’s pretty much it! Let’s run some code now to see this whole framework in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d93aab3-4fe9-41bb-b8c1-4f7722be7a7a",
   "metadata": {},
   "source": [
    "# 4. Hands-On Section\n",
    "Time to implement the whole architecture in practice! Complete code is available on pySearchML repository:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c7bcb-1d51-4d9c-b25b-ec0f3c6f22c7",
   "metadata": {},
   "source": [
    "<img src=\"18.png\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45e842-b3d4-4333-b699-48139faa05bd",
   "metadata": {},
   "source": [
    "In this section, we’ll be using GCP for running the code with real data. Also, keep in mind that there will be costs (a few cents) associated to running this experiment.\n",
    "\n",
    "For those new to GCP, there’s a $300 free credit gift that lasts for a year; just [sign in](https://cloud.google.com/getting-started) and create a project for this tutorial (*pysearchml* for instance). You should end up with access to a dashboard that looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4239573-3ac7-4108-af85-817a1247c8ce",
   "metadata": {},
   "source": [
    "<img src=\"19.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563046ed-c219-473b-9fcc-31cb54e18843",
   "metadata": {},
   "source": [
    "[gcloud](https://cloud.google.com/sdk/install) will be required for interacting with GCP through command line. Installing it is quite straightforward. After the initial setup, make sure you can login by running:\n",
    "\n",
    "***gcloud auth login***\n",
    "\r\n",
    "Now the rest is quite simple. Clone pySearchML to your local:\r\n",
    "\r\n",
    "git clone pysearchml && cd pySearc\n",
    "h[ML\r\n",
    "En](https://console.developers.google.com/apis/library/container.googleapis.com)able Kubernetes Engine in your platform. After that, just trigger the execution[ of cloudb](https://cloud.google.com/cloud-build)uild which will be responsible for creating the whole required infrastructure (this step should take somewhere betwe-n 5~10 minutes).\r\n",
    "\r\n",
    "Here’s ho[w the](https://github.com/WillianFuks/pySearchML/tree/master/kubeflow/build) build triggers the run:\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ef6a1-8352-46f3-b8b8-1a9828b770f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "SUBSTITUTIONS=\\\n",
    "_COMPUTE_ZONE='us-central1-a',\\\n",
    "_CLUSTER_NAME='pysearchml',\\\n",
    "_VERSION='0.0.0'\n",
    "\n",
    "./kubeflow/build/manage_service_account.sh\n",
    "\n",
    "gcloud builds submit --no-source --config kubeflow/build/cloudbuild.yaml --substitutions $SUBSTITUTIONS --timeout=2h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e237f5-5f36-4b06-aaf9-c4fc0b35f140",
   "metadata": {},
   "source": [
    "You can choose appropriate values in the variable *SUBSTITUTIONS*. Notice that *_VERSION* sets the pipeline version to be exported to Kubeflow. After everything is set, just run the script:\n",
    "\n",
    "**./kubeflow/build/build.sh**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51365277-654c-45ee-a4e4-f03260c3d54c",
   "metadata": {},
   "source": [
    "<img src=\"20.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc086d5-8cd8-47f4-8933-2e8e0236ecd7",
   "metadata": {},
   "source": [
    "1.Prepares secret keys to allow access and authorization into GCP tools.\n",
    "2.Prepares known_hosts in building machine.\n",
    "3.Clones pySearchML locally.\n",
    "4.The file [*create_k8.sh*](https://github.com/WillianFuks/pySearchML/blob/master/bin/create_k8s.sh) that runs in step 4 is responsible for creating the Kubernetes cluster on top of Google Kubernetes Engine [(GKE)](https://cloud.google.com/kubernetes-engine) as well as deploying Elasticsearch, Kubeflow and Katib. In parallel, all Docker images required for the system is built and deployed to Google Container Registry [(GCR)](https://cloud.google.com/container-registry) for later use in Kubeflow.\n",
    "5.Run several unittests. Those ended up being important to confirm the system was working as expected. Also, it compiles the Kubeflow pipeline in parallel.\n",
    "6.Finally, deploys the pipeline to the cluster.\n",
    "\n",
    "After it’s done, if you browse to your console and select “Kubernetes Engine”, you’ll see that it’s already up and running:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9f293-ec52-42f0-9c8d-5769e49c8654",
   "metadata": {},
   "source": [
    "<img src=\"21.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e12156-29d2-460f-acb0-6a8d9012256a",
   "metadata": {},
   "source": [
    "It’s a small cluster as we won’t be using much data, this helps to further save on costs.\n",
    "Kubeflow and Katib have already been installed. In order to access it, first connect your gcloud to the cluster by running:\n",
    "\n",
    "***gcloud container clusters get-credentials pysearchml***\n",
    "\n",
    "After that, port-forward the service that deals with Kubeflow to your local by running:\n",
    "\n",
    "***kubectl port-forward -n kubeflow svc/ml-pipeline-ui 8080:80 1>/dev/null &***\n",
    "\n",
    "Now, if you access your localhost on port 8080, this is what you should see:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf02be-f2f2-4baf-b7ca-18befcc71441",
   "metadata": {},
   "source": [
    "<img src=\"22.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55515a-a6cd-42ad-950f-2178146015fc",
   "metadata": {},
   "source": [
    "And the pipeline is ready for execution.\n",
    "\n",
    "This experiment uses the public [Google Analytics sample](https://console.cloud.google.com/marketplace/product/obfuscated-ga360-data/obfuscated-ga360-data?filter=category%3Aanalytics&id=45f150ac-81d3-4796-9abf-d7a4f98eb4c6&project=pysearchml&folder=&organizationId=) dataset and it consists of a small sample of customers browsing on Google Store. It spans from *20160801* up to *20170801* and contains what each user searched and how they interacted with the search results.\n",
    "\n",
    "Select *pysearchml_0.0.0* and then select “+Create Run”. You should see a screen with all possible input parameters as defined in the Python pipeline script. After choosing appropriate parameters, just run the code.\n",
    "\n",
    "After execution, here’s the expected result:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9def67c-c67c-45f2-a4ff-81b28f773680",
   "metadata": {},
   "source": [
    "<img src=\"23.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b3096-ee4a-4d55-81c8-3fca496f19da",
   "metadata": {},
   "source": [
    "#### Output of Katib component:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f0152d-6b7b-43f7-a996-0b9b399682fc",
   "metadata": {},
   "source": [
    "<img src=\"24.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb31fa-c714-485c-8921-ad36471e40d3",
   "metadata": {},
   "source": [
    "We can see a rank of ***36.05%.*** Then, we can compare results from the test component:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d26a3-4f17-45a9-992e-2388c37111b9",
   "metadata": {},
   "source": [
    "<img src=\"25.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b909468-dfb9-4c81-8c1e-a9853c111b78",
   "metadata": {},
   "source": [
    "Rank here is *40.16%* which is a bit worse than validation dataset. It might indicate that the model suffers a bit of over fitting; more data or further parameters exploration might help to alleviate this problem.\n",
    "And, pretty much, there you have it! Elasticsearch now has a fully trained new layer of machine learning to improve results based on context of customers.\n",
    "If you want to navigate through the files created for each step, there’s an available deployment for that. In the pySearchML folder, just run:\n",
    "\n",
    "***kubectl apply -f kubeflow/disk-busybox.yaml***\n",
    "\n",
    "If you run *kubectl -n kubeflow get pods* you’ll see that the name of one of the pods is something like ***“nfs-busybox-(…)”***. If you exec into it you’ll have access to the files:\n",
    "\n",
    "***kubectl -n kubeflow exec -it nfs-busybox-(...) sh***\n",
    "\n",
    "They should be located at */mnt/pysearchml.*\n",
    "There’s also a quick and dirty visualizer for the whole process as well. Just run:\n",
    "\n",
    "***kubectl port-forward service/front -n front 8088:8088 1>/dev/null &***\n",
    "\n",
    "And access your browser in *localhost:8088*. You should see this (quick and ugly) interface:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301e31c-ffc7-4011-a904-0ccd6a250673",
   "metadata": {},
   "source": [
    "<img src=\"26.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0454a-e584-4f74-a271-7966537270c1",
   "metadata": {},
   "source": [
    "Example of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50659c4-6284-4846-9169-d00e01f4b77b",
   "metadata": {},
   "source": [
    "<img src=\"27.jpg\" style=\"Width:400px;Height:400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce59f94-2e27-4604-b700-50d1c35edc09",
   "metadata": {},
   "source": [
    "Not only does it allow to play around with results as well as give us a better sense if the optimization pipeline is working or not.\n",
    "\n",
    "And that’s pretty much all it takes to have a complete search engine running with AI optimization ready to handle income traffic for any store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c35c78-120b-4b42-a095-71657a225a8f",
   "metadata": {},
   "source": [
    "# 5. Conclusion\n",
    "Now, that was a challenge!\n",
    "\n",
    "Building pySearchML was quite tough and I can safely say it was one of the most brutal challenges I’ve ever faced 😅. Countless and countless designs, architectures, infrastructures were considered but most failed.\n",
    "\n",
    "The realization of integrating the whole process on top of Kubeflow and Katib came only later on when several alternatives had already been tested.\n",
    "\n",
    "The advantage of this design is how simple and direct the final code becomes. It’s fully modular, each component is responsible for a simple task and Kubeflow orchestrates the whole execution. On top of that, we can focus mainly in the code development and let Katib do the hard work of finding best parameters.\n",
    "\n",
    "The development process was not straightforward. Several lessons had to be learned including concepts from Kubernetes and its available resources. Still, it was all well worth it. As a result, an entire search engine could be built from scratch with a few lines of code, ready to handle real traffic.\n",
    "\n",
    "As next steps, one could probably consider replacing RankLib with some Deep Learning algorithm which would further extract context from data. One of the main challenges for doing so is that the response time of the system could increase as well as the costs (pros and cons have to be evaluated).\n",
    "\n",
    "Regardless of the ranking algorithm used, the architecture remains the same for the most part.\n",
    "\n",
    "Hopefully, that was a useful post for those working in this field. Now it’s time for us to take some rest, meditate on the lessons learned and prepare ourselves for the next adventure :).\n",
    "\n",
    "As for this post, it certainly deserves being concluded with the mission accomplished [soundtrack.](https://open.spotify.com/playlist/6DDVtTmNRo32PUGy3vsRCC)\n",
    "\n",
    "And, as always,\n",
    "\n",
    "See you in the next mission ;)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
